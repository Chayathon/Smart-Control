import 'dart:async';
import 'dart:typed_data';
import 'package:record/record.dart';
import 'package:web_socket_channel/io.dart';

/// Singleton service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Microphone Streaming ‡πÅ‡∏ö‡∏ö Real-time
/// Optimized ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Raspberry Pi 4 - Low Latency & High Stability
class MicStreamService {
  // Singleton pattern
  static final MicStreamService _instance = MicStreamService._internal();
  factory MicStreamService() => _instance;
  MicStreamService._internal();

  // Core components
  final AudioRecorder _recorder = AudioRecorder();
  IOWebSocketChannel? _channel;
  StreamSubscription<Uint8List>? _micSub;
  StreamSubscription<dynamic>? _wsSub;

  // State management
  bool _isRecording = false;
  bool _isStopping = false;

  // Audio configuration ‚Äì tuned for low latency
  static const int sampleRate = 44100;
  static const int channels = 2;
  // Keep the post-stop silence short to flush server/ffmpeg buffers quickly
  static const int flushTailMs = 200; // ms

  // Callbacks
  void Function(bool isRecording)? onStatusChanged;
  void Function(String error)? onError;

  // Getters
  bool get isRecording => _isRecording;
  bool get isStopping => _isStopping;

  /// ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏ï‡∏£‡∏µ‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á
  Future<bool> startStreaming(String serverUrl) async {
    if (_isRecording || _isStopping) return false;

    if (!await _recorder.hasPermission()) {
      _handleError('‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô');
      return false;
    }

    try {
      // Connect WebSocket
      _channel = IOWebSocketChannel.connect(
        serverUrl,
        pingInterval: const Duration(seconds: 15),
      );

      // Setup WebSocket listener
      _wsSub = _channel!.stream.listen(
        null, // ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å server
        onError: (_) => _handleError('‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß'),
        onDone: () => print('üîå WebSocket closed'),
        cancelOnError: true,
      );

      // Start audio recording
      final stream = await _recorder.startStream(
        const RecordConfig(
          encoder: AudioEncoder.pcm16bits,
          sampleRate: sampleRate,
          numChannels: channels,
          // Note: These DSP features improve audio quality but can cost CPU on low-end devices.
          // If you see high CPU or latency, consider turning off one or more of them.
          autoGain: true,
          echoCancel: true,
          noiseSuppress: true,
        ),
      );

      // Stream audio data to server
      _micSub = stream.listen(
        _sendAudioData,
        onError: (_) => _handleError('‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á'),
        onDone: () => print('üé§ Recording ended'),
      );

      _isRecording = true;
      onStatusChanged?.call(true);
      print('‚úÖ Mic streaming started');
      return true;
    } catch (e) {
      _handleError('‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏ï‡∏£‡∏µ‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: $e');
      await _cleanup();
      return false;
    }
  }

  /// ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á server
  void _sendAudioData(Uint8List data) {
    if (_channel?.closeCode != null) return;
    try {
      _channel!.sink.add(data);
    } catch (e) {
      print('‚ö†Ô∏è Send error: $e');
    }
  }

  /// ‡∏´‡∏¢‡∏∏‡∏î‡∏™‡∏ï‡∏£‡∏µ‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á
  Future<void> stopStreaming() async {
    if (!_isRecording || _isStopping) return;

    _isStopping = true;
    print('üõë Stopping mic stream...');

    try {
      // Stop recording
      await _micSub?.cancel();
      _micSub = null;
      await _recorder.stop();

      // Flush silence tail
      await _flushSilenceTail();

      // Close WebSocket gracefully
      await _channel?.sink.close(1000, 'normal');
      await _wsSub?.cancel();
      _wsSub = null;

      await Future.delayed(const Duration(milliseconds: 100));
    } catch (e) {
      print('‚ö†Ô∏è Stop error: $e');
    } finally {
      await _cleanup();
    }
  }

  /// ‡∏™‡πà‡∏á silence tail ‡πÄ‡∏û‡∏∑‡πà‡∏≠ flush buffer
  Future<void> _flushSilenceTail() async {
    if (_channel?.closeCode != null) return;

    try {
      const int chunkMs = 40;
      final int bytesPerChunk = (sampleRate * channels * 2 * chunkMs) ~/ 1000;
      final silence = Uint8List(bytesPerChunk);
      final chunks = flushTailMs ~/ chunkMs;

      for (int i = 0; i < chunks && _channel?.closeCode == null; i++) {
        _channel?.sink.add(silence);
        await Future.delayed(const Duration(milliseconds: chunkMs));
      }
    } catch (e) {
      print('‚ö†Ô∏è Flush error: $e');
    }
  }

  /// ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ error
  void _handleError(String message) {
    print('‚ùå $message');
    onError?.call(message);
  }

  /// ‡∏•‡πâ‡∏≤‡∏á‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£
  Future<void> _cleanup() async {
    _channel = null;
    _isRecording = false;
    _isStopping = false;
    onStatusChanged?.call(false);
    print('üßπ Cleanup completed');
  }

  /// Toggle ‡∏™‡∏ï‡∏£‡∏µ‡∏°
  Future<bool> toggleStreaming(String serverUrl) async {
    if (_isRecording) {
      await stopStreaming();
      return false;
    }
    return await startStreaming(serverUrl);
  }

  /// ‡∏ó‡∏≥‡∏•‡∏≤‡∏¢ service
  Future<void> dispose() async {
    await stopStreaming();
    await _recorder.dispose();
    print('üóëÔ∏è MicStreamService disposed');
  }
}
